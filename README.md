
# README

Separation and Classification of Heartâ€“Lung Audio from Single-Channel Recordings
*(HLS-CMDS Manikin Dataset)* 

---

## ğŸ“Œ Project Overview

This repository implements a full pipeline for **separating mixed heartâ€“lung audio** and **classifying each separated track**, using the *Heart & Lung Sounds Dataset Recorded from a Clinical Manikin (HLS-CMDS)*.

The workflow is organized into five stages:

1. **Data Loading & Normalization**
2. **Preprocessing & Feature Engineering**
3. **Source Separation** (masking, NMF, smoothing, deep models)
4. **Feature-space Prediction & Reconstruction**
5. **Downstream Classification & Evaluation**

All notebooks live under `notebooks/`. All reusable code lives under `src/`.

---

## ğŸ“‚ Repository Structure

### **data/**

HLS-CMDS dataset arranged by source type:

* `heart_sounds/` â€” 50 clean heart-only WAV files
* `lung_sounds/` â€” 50 clean lung-only WAV files
* `mixed_sounds/` â€” 145 mixtures, each with:

  * `heart_ref/` (ground-truth heart)
  * `lung_ref/` (ground-truth lung)
  * `mixed_ref/` (single-channel mixture)

### **documents/**

* `project_proposal.pdf` â€” motivation, scope, and expected results
* `README.txt`, `prompt.txt` â€” dataset-level annotation from HLS-CMDS
   

### **notebooks/**

Contains all analysis artifacts:

* **data_analysis/** â€” distribution plots, dataset checks, spectrogram examples
* **feature_engineering/** â€” extraction of MFCCs, spectral features, ANOVA sensitivity
* **sound_type_predictions/** â€” logistic regression / RF models on features
* **source_reconstruction/** â€” mask-based and NMF reconstruction
* **model_weights/** â€” currently includes `heart_unet.pth`
* **outputs/**

  * `classification/heart/` and `classification/lung/` â€” metrics, CIs

### **src/**

All reusable pipeline code:

#### **src/audio/**

Low-level audio I/O utilities (load WAV, resample, normalization)

#### **src/features/**

Feature extraction (MFCCs, spectral stats, zero crossings, energy bands)

#### **src/metadata/**

Dataset metadata loading, joins, and visualization tools

#### **src/classification/**

Cross-validated evaluation, CI estimation, confusion matrices, model wrappers

#### **src/feature_prediction/**

Random-forest regressors that predict latent heart/lung features from mixed sources

#### **src/reconstruction/**

Feature-space â†’ waveform reconstruction, NMF utilities, masks, smoothing

#### **src/prediction_pipeline/**

End-to-end pipeline:
mixed WAV â†’ feature extraction â†’ RF mapping â†’ classifier â†’ predictions

---

## â–¶ï¸ How to Run

### **1. Install dependencies**

```bash
pip install -r requirements.txt
```

This will install:

* `numpy`, `scipy`, `librosa`
* `pandas`, `matplotlib`, `seaborn`
* `scikit-learn`
* `tqdm`
* `torch` (for UNet-based separation)

### **2. Recommended execution order**

#### **Stage 1 â€” Data Exploration**

`notebooks/data_analysis/data_analysis.ipynb`
Checks distributions, metadata consistency, spectrograms, and audio sanity.

#### **Stage 2 â€” Feature Engineering**

`notebooks/feature_engineering/feature_engineering.ipynb`
Extracts MFCC/spectral features and runs ANOVA factor-sensitivity.

#### **Stage 3 â€” Source Separation**

`notebooks/source_reconstruction/source_reconstruction.ipynb`
Runs:

* STFT masking
* NMF (standard & KL divergence)
* optional UNet baseline

Outputs reconstructed heart/lung WAV files.

#### **Stage 4 â€” Feature Prediction / Regression**

`notebooks/source_feature_prediction.ipynb`
Random-forest regression to map mixed features â†’ clean heart/lung features.

#### **Stage 5 â€” Classification**

`notebooks/classification.ipynb`
Logistic/Random-Forest/GMM/KNN, K-fold CV, bootstrap confidence intervals.

---

## ğŸ“ Formatting Notes

* All notebooks follow the same structure:
  **Goal â†’ Methods â†’ Experiments â†’ Results â†’ Discussion â†’ Next Steps**
* Code is modular: all logic lives in `src/`, notebooks call these functions.
* Figures are exported automatically to `notebooks/outputs/`.

---

## ğŸ“š References

Dataset and proposal descriptions are included:

* Proposal: 
* Dataset README: 
